// light block with no workflow
wf := import("@platforma-sdk/workflow-tengo:workflow")
file := import("@platforma-sdk/workflow-tengo:file")
exec := import("@platforma-sdk/workflow-tengo:exec")
assets:= import("@platforma-sdk/workflow-tengo:assets")
xsv := import("@platforma-sdk/workflow-tengo:pframes.xsv")
pframes := import("@platforma-sdk/workflow-tengo:pframes")
pSpec := import("@platforma-sdk/workflow-tengo:pframes.spec")
slices := import("@platforma-sdk/workflow-tengo:slices")
pt := import("@platforma-sdk/workflow-tengo:pt")

prepareFastaSw := assets.importSoftware("@platforma-open/milaboratories.immune-assay-data.prepare-fasta:main")
mmseqsSw := assets.importSoftware("@platforma-open/soedinglab.software-mmseqs2:main")
addHeaderSw := assets.importSoftware("@platforma-open/milaboratories.immune-assay-data.add-header:main")

wf.prepare(func(args){
	bundleBuilder := wf.createPBundleBuilder()
	bundleBuilder.addAnchor("main", args.datasetRef) 
	bundleBuilder.addSingle(args.targetRef)
	return {
		columns: bundleBuilder.build()
	}
})

prepareAssayTsv := func(args, file) {
	// assign ids to assay sequences
	ptw := pt.workflow()
	df := ptw.frame({
		file: file,
		xsvType: "tsv" // @TODO (!!!)
	})

	//////// calculate sequence id ////////
	df = df.addColumns(
		pt.col(args.sequenceColumnHeader).hash("sha256", "base64_alphanumeric", 120).alias("seqId")
	)
	//////// add label to ids ////////
	df = df.withColumns(
        pt.col("seqId").
            strReplace("\\d", "", { replaceAll: true }).
            strSlice(0, 5).               // Take first 5 characters
            strToUpper().                 // Convert to uppercase
            alias("tmpLabel")
    )
	df = df.withColumns(
        pt.rank(pt.col("seqId")).  // Rank based on clonotypeKeyCol (default ascending)
            over(pt.col("tmpLabel")).   // Partition by prefixTempCol
            alias("rank")
    )
	df = df.withColumns(
        pt.when(pt.col("rank").gt(pt.lit(1))).
            then(pt.concatStr([pt.lit("A"), pt.col("tmpLabel"), pt.col("rank").cast("String")], { delimiter: "-" })).
            otherwise(pt.concatStr([pt.lit("A"), pt.col("tmpLabel")], { delimiter: "-" })).
            alias("seqIdLabel")
    )
	df = df.withoutColumns("rank", "tmpLabel")

	//////// add sequence column ////////
	df = df.addColumns(
		pt.col(args.sequenceColumnHeader).alias("sequence")
	)
	df.save("output.tsv")
	
	return ptw.run().getFile("output.tsv")
}

prepareClonesTsv := func(args, file) {
	columns := args.columns
	datasetSpec := columns.getSpec(args.datasetRef)

	cloneTable := pframes.tsvFileBuilder()
	
	cloneTable.setAxisHeader(datasetSpec.axesSpec[1].name, "seqId")
	cloneTable.add(columns.getColumn(args.targetRef), {header: "sequence"})

	return cloneTable.build()
}

prepareFasta := func(fileTsv) {
	return exec.builder().
		software(prepareFastaSw).
		addFile("input.tsv", fileTsv).
		arg("-i").arg("input.tsv").
		arg("-o").arg("output.fasta").
		arg("--seq_col").arg("sequence").
		arg("--id_col").arg("seqId").
		saveFile("output.fasta").
		run().
		getFile("output.fasta")
}

wf.body(func(args) {
	importFile := file.importFile(args.fileHandle)
	assayTsv := prepareAssayTsv(args, importFile.file)
	clonesTsv := prepareClonesTsv(args, importFile.file)


	// prepare fasta file
	assayFasta := prepareFasta(assayTsv)
	clonesFasta := prepareFasta(clonesTsv)

	// run search
	mmseqs := exec.builder().
		software(mmseqsSw).
		dontSaveStdoutOrStderr(). // important to avoid CID conflict problems coming from different stdout output on same datasets
		arg("easy-search").
		arg("clones.fasta").
		arg("assay.fasta").
		arg("results.tsv").
		arg("tmp").
		addFile("clones.fasta", clonesFasta).
		addFile("assay.fasta", assayFasta).
		saveFile("results.tsv").
		run()

	mmseqsOutput := mmseqs.getFile("results.tsv")
	// @TODO remove header stuff and replace with pt when available (!)
	mmseqsResultTsv := exec.builder().
		software(addHeaderSw).
		arg("-i").arg("results.tsv").
		arg("-o").arg("results_with_header.tsv").
		addFile("results.tsv", mmseqsOutput).
		saveFile("results_with_header.tsv").
		run().
		getFile("results_with_header.tsv")


	//////// Process tables ////////

	ptw := pt.workflow()
	df := ptw.frame({
		file: mmseqsResultTsv,
		xsvType: "tsv"
	})

	cols := []
	for _, col in ["bits", "evalue", "target", "pident", "alnlen", "mismatch", "gapopen", "qstart", "qend", "tstart", "tend"] {
		cols = append(cols,
					  pt.col(col).maxBy(
							pt.col("evalue").multiply(-1),
							pt.col("bits")
					  	).alias(col)
					  )
	}
	
	df = df.groupBy("query").agg(cols...)
	df.save("results.tsv")

	// assay data import summary
	assayDf := ptw.frame({
		file: assayTsv,
		xsvType: "tsv"
	})
	// import how many matches per assay sequence found
	assayDf = assayDf.join(
		df.groupBy("target").agg(
			pt.col("query").count().alias("queryCount")
		),
		{
			how: "left",
			leftOn: "seqId",
			rightOn: "target"
		}
	)
	assayDf.save("assayData.tsv")

	// clones 
	clonesDf := df.join(assayDf,
		{
			how: "left",
			leftOn: "target",
			rightOn: "seqId"
		}
	)

	clonesDf.save("clonesData.tsv")
	ptw = ptw.run()
	
	//////// Building outputs & exports ////////
	blockId := wf.blockId().getDataAsJson()

	assayColumns := [
		{
			column: "seqIdLabel",
			spec: {
				name: "pl7.app/label",
				valueType: "String",
				annotations: {
					"pl7.app/label": "Sequence Id",
					"pl7.app/table/fontFamily": "monospace"
				}
			}
		},	
		{
			column: "queryCount",
			spec: {
				name: "pl7.app/vdj/assay/queryCount",
				valueType: "Int",
				annotations: {
					"pl7.app/label": "Matched Clones",
					"pl7.app/table/orderPriority": "9000"
				}
			}
	}]
	for h in args.headers {
		assayColumns = append(assayColumns, {
			column: h,
			spec: {
				name: h,
				valueType: "String",
				annotations: {	
					"pl7.app/label": h,
					"pl7.app/table/orderPriority": h == args.sequenceColumnHeader ? "10000" : "1000"
				}
			}
		})
	}

	assayImportResults := xsv.importFile(ptw.getFile("assayData.tsv"), "tsv", {
		axes: [{
			column: "seqId",
			spec: {
				name: "pl7.app/vdj/assay/sequenceId",
				type: "String",
				domain: {
					"pl7.app/blockId": blockId
				},
				annotations: {
					"pl7.app/label": "Sequence Id",
					"pl7.app/table/fontFamily": "monospace"
				}
			}
		}],
		columns: assayColumns,
		annotations: {
			"pl7.app/isAnchor": "true"
		}
	})

    // "bits", "evalue", "pident"
	cloneColumns := [
	{
		column: "target",
		spec: {
			name: "pl7.app/vdj/assay/sequenceId",
			valueType: "String",
			domain: {
				"pl7.app/blockId": blockId
			},
			annotations: {
				"pl7.app/label": "Assay Sequence Id",
				"pl7.app/table/defaultVisibility": "optional"
			}
		}
	},
	{
		column: "bits",
		spec: {
			name: "pl7.app/alignment/bitScore",
			valueType: "Float",
			domain: {
				"pl7.app/blockId": blockId
			},
			annotations: {
				"pl7.app/label": "Bit Score",
				"pl7.app/table/defaultVisibility": "optional"
			}
		}
	},
	{
		column: "evalue",
		spec: {
			name: "pl7.app/alignment/evalue",
			valueType: "Float",
			domain: {
				"pl7.app/blockId": blockId
			},
			annotations: {
				"pl7.app/label": "E-value",
				"pl7.app/table/defaultVisibility": "optional"
			}
		}
	},
	{
		column: "pident",
		spec: {
			name: "pl7.app/alignment/pident",
			valueType: "Float",
			domain: {
				"pl7.app/blockId": blockId
			},
			annotations: {
				"pl7.app/label": "Percentage of identical matches",
				"pl7.app/table/defaultVisibility": "optional"
			}
		}
	}]

	for h in args.headers {
		cloneColumns = append(cloneColumns, {
			column: h,
			spec: {
				name: h,
				valueType: "String",
				annotations: {	
					"pl7.app/label": h,
					"pl7.app/table/defaultVisibility": h == args.sequenceColumnHeader ? "optional" : "default"
				}
			}
		})
	}

    datasetSpec := args.columns.getSpec(args.datasetRef)
	cloneImportResults := xsv.importFile(
		ptw.getFile("clonesData.tsv"), "tsv", {
			axes: [{
				column: "query",
				spec: datasetSpec.axesSpec[1]
			}],
			columns: cloneColumns
		},
		{ splitDataAndSpec: true }
	)

	trace := pSpec.makeTrace(datasetSpec,
        {
            type: "milaboratories.clonotype-enrichment",
            importance: 30,
            label: "Clonotype enrichment"
        })

	epf := pframes.pFrameBuilder()
	for k, v in cloneImportResults {
		epf.add(k, trace.inject(v.spec), v.data)
	}
	epf = epf.build()
	
	return {
		outputs: {
			dataImportHandle: importFile.handle,
			table: pframes.exportFrame(assayImportResults),
			mmseqsOutput: mmseqsOutput // @TODO tmp fix to resolve CID conflicts
		},
		exports: {
			epf: epf
		}
	}
})
